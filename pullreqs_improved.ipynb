{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting pull request merges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will attempt to predict whether a pull request will be merged. The dataset we will be using is a newer version of the one published at MSR 2014 by [Gousios and Zaidman](http://gousios.org/bibliography/GZ14.html),\n",
    "available [here](https://drive.google.com/open?id=0B9Rx0uhucsroV196OEp5VGhzSkU). The dataset comes in CSV format.\n",
    "\n",
    "For this task, we will be using PySpark and the Spark ML library, to demonstrate\n",
    "how nicely Spark integrates with the extremely rich Python Data Science/Big Data ecosystem.\n",
    "\n",
    "We begin our exploration by importing typical libraries from the Python world:\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org) Implements data frame functionality, which enables us to manipulate data in a tabular format using our well-trusted higher-order functions.\n",
    "* [MatPlotLib](https://matplotlib.org) Implements programmatic plotting functionality, acts as the backend for all graphics utilities in Python \n",
    "* [GGPlot](http://ggplot.yhathq.com) A principled way for creating statistical plots, based on the [Grammar for Graphics](http://www.springer.com/gp/book/9780387245447)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to our previous examples, we will be using higher level components; one of them is the Spark CSV reader. This allows us to read a CSV file into a Spark Dataframe in one line; most importantly, it can automatically infer the schema (data types) from our CSV, which saves us lots of boring work! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(\"dataset_v2.csv\", \n",
    "                         sep=\",\", \n",
    "                         header=True, \n",
    "                         inferSchema=True).cache()\n",
    "aux = df.toPandas()\n",
    "names = []\n",
    "for i, row in aux.groupby('project_name').size().iteritems():\n",
    "    if row > 50:\n",
    "        names.append(i)\n",
    "        \n",
    "aux = aux.loc[aux['project_name'].isin(names)]\n",
    "aux['mergetime_minutes'] = aux['mergetime_minutes'].fillna(0.0);\n",
    "aux['merged'] = aux['mergetime_minutes'].where(aux['mergetime_minutes'].isnull() | aux['mergetime_minutes'] == 0.0, True).fillna(False).astype(bool)\n",
    "df = sqlContext.createDataFrame(aux)\n",
    "sqlContext.registerDataFrameAsTable(df, \"pullreqs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also using Spark's `SQLContext` instead of our typical `SparkContext`. This allows us to run SQL queries directly on top our CSV data! Spark will in the background distribute the processing load on all workers. \n",
    "\n",
    "PySpark is integrated to the [Pydata](http://pydata.org) ecosystem; this allows us to use the `toPandas()` function,\n",
    "which will convert a distributed Spark DataFrame to a local Pandas dataframe. The are many legitimate reasons for\n",
    "which this is a good thing: we can for example use the data for plotting or apply some [sckit-learn](http://scikit-learn.org/) machine learning algorith on top of it. In our case, we exploit the fact that Jupyter, our notebook system, knows about Pandas dataframes to print the results locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the columns in our CSV file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pull_req_id: long (nullable = true)\n",
      " |-- project_name: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- github_id: long (nullable = true)\n",
      " |-- created_at: long (nullable = true)\n",
      " |-- merged_at: double (nullable = true)\n",
      " |-- closed_at: long (nullable = true)\n",
      " |-- lifetime_minutes: long (nullable = true)\n",
      " |-- mergetime_minutes: double (nullable = true)\n",
      " |-- merged_using: string (nullable = true)\n",
      " |-- conflict: boolean (nullable = true)\n",
      " |-- forward_links: boolean (nullable = true)\n",
      " |-- intra_branch: boolean (nullable = true)\n",
      " |-- description_length: long (nullable = true)\n",
      " |-- num_commits: long (nullable = true)\n",
      " |-- num_commits_open: long (nullable = true)\n",
      " |-- num_pr_comments: long (nullable = true)\n",
      " |-- num_issue_comments: long (nullable = true)\n",
      " |-- num_commit_comments: long (nullable = true)\n",
      " |-- num_comments: long (nullable = true)\n",
      " |-- num_commit_comments_open: long (nullable = true)\n",
      " |-- num_participants: long (nullable = true)\n",
      " |-- files_added_open: long (nullable = true)\n",
      " |-- files_deleted_open: long (nullable = true)\n",
      " |-- files_modified_open: long (nullable = true)\n",
      " |-- files_changed_open: long (nullable = true)\n",
      " |-- src_files_open: long (nullable = true)\n",
      " |-- doc_files_open: long (nullable = true)\n",
      " |-- other_files_open: long (nullable = true)\n",
      " |-- files_added: long (nullable = true)\n",
      " |-- files_deleted: long (nullable = true)\n",
      " |-- files_modified: long (nullable = true)\n",
      " |-- files_changed: long (nullable = true)\n",
      " |-- src_files: long (nullable = true)\n",
      " |-- doc_files: long (nullable = true)\n",
      " |-- other_files: long (nullable = true)\n",
      " |-- src_churn_open: long (nullable = true)\n",
      " |-- test_churn_open: long (nullable = true)\n",
      " |-- tests_added_open: long (nullable = true)\n",
      " |-- tests_deleted_open: long (nullable = true)\n",
      " |-- tests_added: long (nullable = true)\n",
      " |-- tests_deleted: long (nullable = true)\n",
      " |-- src_churn: long (nullable = true)\n",
      " |-- test_churn: long (nullable = true)\n",
      " |-- new_entropy: double (nullable = true)\n",
      " |-- entropy_diff: double (nullable = true)\n",
      " |-- commits_on_files_touched: long (nullable = true)\n",
      " |-- commits_to_hottest_file: long (nullable = true)\n",
      " |-- hotness: double (nullable = true)\n",
      " |-- at_mentions_description: long (nullable = true)\n",
      " |-- at_mentions_comments: long (nullable = true)\n",
      " |-- perc_external_contribs: double (nullable = true)\n",
      " |-- sloc: long (nullable = true)\n",
      " |-- test_lines: long (nullable = true)\n",
      " |-- test_cases: long (nullable = true)\n",
      " |-- asserts: long (nullable = true)\n",
      " |-- stars: long (nullable = true)\n",
      " |-- team_size: long (nullable = true)\n",
      " |-- workload: long (nullable = true)\n",
      " |-- ci: string (nullable = true)\n",
      " |-- requester: string (nullable = true)\n",
      " |-- closer: string (nullable = true)\n",
      " |-- merger: string (nullable = true)\n",
      " |-- prev_pullreqs: long (nullable = true)\n",
      " |-- requester_succ_rate: double (nullable = true)\n",
      " |-- followers: long (nullable = true)\n",
      " |-- main_team_member: boolean (nullable = true)\n",
      " |-- social_connection: boolean (nullable = true)\n",
      " |-- prior_interaction_issue_events: long (nullable = true)\n",
      " |-- prior_interaction_issue_comments: long (nullable = true)\n",
      " |-- prior_interaction_pr_events: long (nullable = true)\n",
      " |-- prior_interaction_pr_comments: long (nullable = true)\n",
      " |-- prior_interaction_commits: long (nullable = true)\n",
      " |-- prior_interaction_commit_comments: long (nullable = true)\n",
      " |-- first_response: long (nullable = true)\n",
      " |-- merged: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "# df.groupBy('project_name').count().toPandas()\n",
    "# df.select('mergetime_minutes').where('mergetime_minutes is null').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|        merged_using|occurences|\n",
      "+--------------------+----------+\n",
      "|        merge_button|      7883|\n",
      "|   commits_in_master|      7109|\n",
      "|             unknown|       335|\n",
      "|  merged_in_comments|        23|\n",
      "|commit_sha_in_com...|        19|\n",
      "|     fixes_in_commit|         8|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"select merged_using, count(*) as occurences \n",
    "                  from pullreqs \n",
    "                  group by merged_using \n",
    "                  order by occurences desc\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above SQL query can be also defined programmatically. At the background, Spark is compiling SQL to a series of calls like the ones we show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|        merged_using|count(merged_using)|\n",
      "+--------------------+-------------------+\n",
      "|        merge_button|             182424|\n",
      "|   commits_in_master|             105378|\n",
      "|             unknown|               7318|\n",
      "|commit_sha_in_com...|               1128|\n",
      "|  merged_in_comments|                307|\n",
      "|     fixes_in_commit|                 39|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.\\\n",
    "    groupBy(df.merged_using).\\\n",
    "    agg({'merged_using': 'count'}).\\\n",
    "    orderBy(desc(\"count(merged_using)\")).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many projects and languages are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|num_projects|\n",
      "+------------+\n",
      "|         749|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"select count(distinct(project_name)) as num_projects \n",
    "                  from pullreqs\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but how many projects are there per programming language? Let's do a quick SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      lang|num_projects|\n",
      "+----------+------------+\n",
      "|JavaScript|         255|\n",
      "|    Python|         192|\n",
      "|      Java|         159|\n",
      "|      Ruby|         128|\n",
      "|     Scala|          15|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"select lang, count(*) as num_projects \n",
    "                  from (\n",
    "                      select distinct(project_name), lang \n",
    "                      from pullreqs\n",
    "                  ) as project_langs\n",
    "                  group by lang\n",
    "                  order by num_projects desc\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do exactly the same query using Dataframe transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      lang|count(lang)|\n",
      "+----------+-----------+\n",
      "|      Java|         41|\n",
      "|    Python|         25|\n",
      "|      Ruby|         12|\n",
      "|JavaScript|          2|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"project_name\"], df[\"lang\"]).\\\n",
    "    distinct().\\\n",
    "    groupBy(df[\"lang\"]).\\\n",
    "    agg({\"lang\":\"count\"}).\\\n",
    "    orderBy(\"count(lang)\", ascending=False).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to close pull requests (external contributors) - box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c20a58250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.select('mergetime_minutes').\\\n",
    "    where('mergetime_minutes > 0.0 and main_team_member = false').\\\n",
    "    toPandas().\\\n",
    "    apply(np.log)\n",
    "    \n",
    "ax2 = df.select('mergetime_minutes').\\\n",
    "    where('mergetime_minutes > 0.0 and main_team_member = true').\\\n",
    "    toPandas().\\\n",
    "    apply(np.log)\n",
    "\n",
    "\n",
    "plt.boxplot([ax, ax2])\n",
    "plt.xticks([1, 2], ['external', 'core'])\n",
    "plt.title('Merge time external contributors vs core members')\n",
    "\n",
    "plt.savefig('box.png', dpi=400)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the PR distribution per project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAHvCAYAAABKXSdNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3WtwnPV58OFb0q5WByNrDWsb25wPjgwVGE06pYQYG2gT\nMAdPKSR8IGE6bWlaOj2kTWfodNKZTNqGJO2Hpu10mJZpcyhlYCZgm3QIccSQUAZMjUiBNGBioD4J\nH9BIsndXst4P1HqRsbEUrbT6P7quL7Z2V8/euzcKPzaPdhvGxsbGAgAAEtZY7wEAAGC6RC0AAMkT\ntQAAJE/UAgCQPFELAEDyRC0AAMnLzfYd7ty5s+bHzOfzUSqVor+/P6rVas2PP1cUCoUol8v1HmPG\n2GM22GM22GM22GN2zNQuly1bVrNj1ZtXahPS2GhdWWCP2WCP2WCP2WCPRIhaAAAyQNQCAJA8UQsA\nQPJELQAAyRO1AAAkT9QCAJA8UQsAQPJELQAAyRO1AAAkT9QCAJA8UQsAQPJELQAAyRO1AAAkT9QC\nAJA8UQsAQPJELQAAyRO1AAAkT9QCAJC8XL0HmGk33nhjvUeYUY888ki9RwAAqDuv1AIAkDxRCwBA\n8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACQvN5kb\n/fM//3O89dZb0dj4bgN3dHTE3XffHRERfX198cQTT8Tw8HCce+65cdNNN0VbW9vMTQwAAMeYVNRG\nRFx33XXR09Mz4bK9e/fGxo0b4/bbb4/TTz89Hn300di0aVP86q/+as0HBQCAE5l01B5PX19fXHjh\nhXH22WdHRMS6devib//2b6NcLkehUIiBgYEYHByc8D2VSiXa29unc7fvk8vlJvw5n+Tz+XqPUDPz\nZY9NTU2Z2tux7DEb7DEb7DE75ssup2PSz8wTTzwR3/3ud+O0006LdevWxTnnnBP9/f1xxhlnjN9m\n0aJF0dTUFPv27Ytly5bF1q1bo7e3d8Jx1qxZE2vXrq3dI3iPYrE4I8edy0qlUr1HqLn5uMcsssds\nsMdssMfssMsTm1TUXnvttVEqlaKpqSl+9KMfxbe+9a246667olKpRKFQmHDblpaWKJfLERHR09MT\nK1eunHB9pVKJ/v7+Go3/rlwuF8ViMQ4cOBAjIyM1PfZcV+vnsp7myx4LhcL4z0gW2WM22GM22GN2\nzNQus/Ti2KSidsWKFeN/v/TSS+PFF1+Mn/zkJ9Hc3Py+f4iOnnoQ8e4vlHV0dEy4fufOnVGtVqc7\n93GNjIzM2LHnqiw+3qzvMZfLZfrxHWWP2WCP2WCP2ZH1XU7Hz/SWXg0NDTE2NhalUin27Nkzfvn+\n/ftjZGQkTj311JoNCAAAJ3PSqD106FC8+uqrUa1WY3R0NPr6+mLHjh1x/vnnR3d3d/z4xz+OHTt2\nRKVSiS1btkRXV9f7TkkAAICZdNLTD44cORLf+9734u23346GhoY47bTT4hOf+EScdtppERGxfv36\neOihh+LQoUPj71MLAACz6aRR297eHr/xG79xwuu7u7uju7u7pkMBAMBU+JhcAACSJ2oBAEieqAUA\nIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oB\nAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5Ila\nAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSl5vtOywUCtHYWNuW\nbmhoiOHh4cjn85HLzfpDqqvW1tZ6j1Az82WPjY2NmdrbsewxG+wxG+wxO+bLLqdj1p+Vcrlc82Pm\n8/no7OyMoaGhqFarNT/+XHbo0KF6j1Az82WPra2tmdrbsewxG+wxG+wxO2Zql8VisWbHqjenHwAA\nkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UA\nACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQt\nAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxR\nCwBA8nJTufG+ffvi7/7u72LVqlXxK7/yKxER0dfXF0888UQMDw/HueeeGzfddFO0tbXNyLAAAHA8\nU3qldtOmTbF8+fLxr/fu3RsbN26MDRs2xGc/+9nI5/OxadOmmg8JAAAfZNJR++KLL0ZLS0ucc845\n45f19fXFhRdeGGeffXYUCoVYt25dvPzyy1Eul2dkWAAAOJ5JnX5w+PDh2LJlS3zqU5+K559/fvzy\n/v7+OOOMM8a/XrRoUTQ1NcW+ffti2bJlMTAwEIODgxOOValUor29vUbjvyuXy034cz7J5/P1HqFm\n5ssem5qaMrW3Y9ljNthjNthjdsyXXU7HpJ6ZLVu2xGWXXRYLFy6ccHmlUolCoTDhspaWlvFXardu\n3Rq9vb0Trl+zZk2sXbt2OjOfULFYnJHjzmWlUqneI9TcfNxjFtljNthjNthjdtjliZ00anft2hXb\nt2+P3/zN33zfdc3Nze871aBcLo+Hbk9PT6xcuXLC9ZVKJfr7+6cz8/vkcrkoFotx4MCBGBkZqemx\n57paP5f1NF/2WCgUMn2Kjj1mgz1mgz1mx0ztMksvjp00an/605/GwYMH46//+q8j4t0oHRsbi3/4\nh3+I888/P/bs2TN+2/3798fIyEiceuqpERHR0dERHR0dE463c+fOqFartXwM40ZGRmbs2HNVFh9v\n1veYy+Uy/fiOssdssMdssMfsyPoup+OkUdvT0xMXX3zx+Nc//OEP4+DBg7F+/foYGhqK++67L3bs\n2BGnn356bNmyJbq6ut53SgIAAMykk0Ztc3NzNDc3T/g6l8tFe3t7tLe3x/r16+Ohhx6KQ4cOjb9P\nLQAAzKYp/wrdsb/k1d3dHd3d3TUbCAAApsrH5AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA\n8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIA\nkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8kQtAADJE7UA\nACRP1AIAkDxRCwBA8kQtAADJE7UAACRP1AIAkDxRCwBA8nKzfYeFQiEaG2vb0g0NDTE8PBz5fD5y\nuVl/SHXV2tpa7xFqZr7ssbGxMVN7O5Y9ZoM9ZoM9Zsd82eV0zPqzUi6Xa37MfD4fnZ2dMTQ0FNVq\ntebHn8sOHTpU7xFqZr7ssbW1NVN7O5Y9ZoM9ZoM9ZsdM7bJYLNbsWPXm9AMAAJInagEASJ6oBQAg\neaIWAIDkiVoAAJInagEASJ6oBQAgeaIWAIDkiVoAAJInagEASJ6oBQAgeaIWAIDkiVoAAJInagEA\nSJ6oBQAgeaIWAIDkiVoAAJInagEASJ6oBQAgeaIWAIDkiVoAAJInagEASJ6oBQAgeaIWAIDkiVoA\nAJInagEASJ6oBQAgeaIWAIDkiVoAAJInagEASJ6oBQAgeaIWAIDkiVoAAJInagEASF5uMjd66KGH\n4vXXX49KpRILFiyIK664Inp6eiIiYvv27bFp06Z45513YsWKFXHzzTdHZ2fnjA4NAADvNamovfLK\nK+Omm26KXC4X/f39cf/998fpp58eCxcujAceeCBuvPHGuPDCC2PLli3x4IMPxq//+q/P9NwAADBu\nUqcfLF68OHK5d/u3oaEhGhoaYv/+/fHyyy9HqVSKiy66KPL5fFx11VWxZ8+e6O/vn9GhAQDgvSb1\nSm1ExMaNG2Pbtm0xMjISS5cujQsuuCC+973vxdKlS8dv09zcHMViMfr7+6NUKsXAwEAMDg5OOE6l\nUon29vbaPYKI8eA++ud8ks/n6z1CzcyXPTY1NWVqb8eyx2ywx2ywx+yYL7ucjkk/M+vXr4/rrrsu\n3nzzzfjpT38auVwuKpVKtLW1TbhdS0tLlMvliIjYunVr9Pb2Trh+zZo1sXbt2hqM/n7FYnFGjjuX\nlUqleo9Qc/Nxj1lkj9lgj9lgj9lhlyc2pdxvbGyMs846K/r6+uLZZ5+N5ubm8YA9qlwuR6FQiIiI\nnp6eWLly5YTrK5VKzU9PyOVyUSwW48CBAzEyMlLTY891WTrVY77ssVAovO/nJkvsMRvsMRvsMTtm\napdZenHsZ3oN+8iRI3HgwIEolUrxwgsvjF9eqVRi//79409QR0dHdHR0TPjenTt3RrVancbIJzYy\nMjJjx56rsvh4s77HXC6X6cd3lD1mgz1mgz1mR9Z3OR0n/UWxwcHBePHFF6NcLseRI0fi1VdfjR/9\n6EdxzjnnRFdXV+zduzdeeumlqFar0dvbG0uWLMlU9QMAMPed9JXahoaGeO6552Ljxo0xNjYWnZ2d\n8bGPfSw+9KEPRUTErbfeGps3b46HH344li9fHrfccsuMDw0AAO910qhtb2+PO++884TXn3feeXH3\n3XfXdCgAAJgKH5MLAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDy\nRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQ\nPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAA\nJE/UAgCQPFELAEDycrN9h4VCIRoba9vSDQ0NMTw8HPl8PnK5WX9IddXa2lrvEWpmvuyxsbExU3s7\nlj1mgz1mgz1mx3zZ5XTM+rNSLpdrfsx8Ph+dnZ0xNDQU1Wq15sefyw4dOlTvEWpmvuyxtbU1U3s7\nlj1mgz1mgz1mx0ztslgs1uxY9eb0AwAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5\nohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBI\nnqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAA\nkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5uZPdYGRkJDZt2hTbt2+PQ4cOxaJFi+Lq\nq6+OCy64ICIitm/fHps2bYp33nknVqxYETfffHN0dnbO+OAAAHDUSV+pPXLkSHR0dMSnP/3p+JM/\n+ZNYu3ZtPPjgg3HgwIEYGhqKBx54INatWxef+9znYtmyZfHggw/OxtwAADDupK/UNjc3x9q1a8e/\nXrlyZXR2dsauXbtieHg4SqVSXHTRRRERcdVVV8WXvvSl6O/vj1KpFAMDAzE4ODjheJVKJdrb22v7\nIHK5CX/OJ/l8vt4j1Mx82WNTU1Om9nYse8wGe8wGe8yO+bLL6ZjyMzM4OBj79u2LUqkUzz33XCxd\nunT8uubm5igWi+NRu3Xr1ujt7Z3w/WvWrJkQybVULBZn5LhzWalUqvcINTcf95hF9pgN9pgN9pgd\ndnliU4ra0dHReOihh+LSSy+NUqkUlUol2traJtympaUlyuVyRET09PTEypUrJ1xfqVSiv79/mmNP\nlMvlolgsxoEDB2JkZKSmx57rav1c1tN82WOhUBj/Gckie8wGe8wGe8yOmdplll4cm3TUHjlyJB5+\n+OFoamqK6667LiLefWX22H+IyuVyFAqFiIjo6OiIjo6OCdfv3LkzqtXqdOc+rpGRkRk79lyVxceb\n9T3mcrlMP76j7DEb7DEb7DE7sr7L6ZjUW3qNjY3FI488EkNDQ3HbbbdFU1NTRLxb93v27Bm/XaVS\nif3792eq+gEAmPsmFbUbN26M/v7++OQnPznhROyurq7Yu3dvvPTSS1GtVqO3tzeWLFkiagEAmFUn\nPf3g4MGDsXXr1mhqaoovf/nL45ffcMMN0d3dHbfeemts3rw5Hn744Vi+fHnccsstMzowAAAc66RR\n29nZGZ///OdPeP15550Xd999dy1nAgCAKfExuQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQ\nPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAA\nJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0A\nAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJC8323dYKBSisbG2Ld3Q0BDDw8ORz+cjl5v1h1RX\nra2t9R6hZubLHhsbGzO1t2PZYzbYYzbYY3bMl11Ox6w/K+VyuebHzOfz0dnZGUNDQ1GtVmt+/Lns\n0KFD9R6hZubLHltbWzO1t2PZYzbYYzbYY3bM1C6LxWLNjlVvTj8AACB5ohYAgOSJWgAAkidqAQBI\nnqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAA\nkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYA\ngOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOTlJnOjZ555JrZt2xZ7\n9+6Niy++ODZs2DB+3fbt22PTpk3xzjvvxIoVK+Lmm2+Ozs7OGRsYAACONalXak855ZT46Ec/GqtX\nr55w+dDQUDzwwAOxbt26+NznPhfLli2LBx98cEYGBQCAE5lU1K5atSq6urqitbV1wuUvv/xylEql\nuOiiiyKfz8dVV10Ve/bsif7+/hkZFgAAjmdSpx+cSH9/fyxdunT86+bm5igWi9Hf3x+lUikGBgZi\ncHBwwvdUKpVob2+fzt2+Ty6Xm/DnfJLP5+s9Qs3Mlz02NTVlam/HssdssMdssMfsmC+7nI5pPTOV\nSiXa2tomXNbS0hLlcjkiIrZu3Rq9vb0Trl+zZk2sXbt2Ond7QsVicUaOO5eVSqV6j1Bz83GPWWSP\n2WCP2WCP2WGXJzatqG1ubh4P2KPK5XIUCoWIiOjp6YmVK1dOuL5SqdT89IRcLhfFYjEOHDgQIyMj\nNT32XJelUz3myx4LhcL7fm6yxB6zwR6zwR6zY6Z2maUXx6YVtaVSKV544YXxryuVSuzfv3/8Cero\n6IiOjo4J37Nz586oVqvTudsTGhkZmbFjz1VZfLxZ32Mul8v04zvKHrPBHrPBHrMj67ucjkn9otjo\n6GhUq9UYGxuLsbGxqFarMTo6Gl1dXbF379546aWXolqtRm9vbyxZsiRT1Q8AwNw3qVdqn3zyyQnn\nxvb19Y2fG3vrrbfG5s2b4+GHH47ly5fHLbfcMmPDAgDA8UwqateuXXvCX+4677zz4u67767pUAAA\nMBU+JhcAgOSJWgAAkucdfBN344031nuEGfXII4/UewQAIAFeqQUAIHmiFgCA5IlaAACSJ2oBAEie\nqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACS\nJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSJ2oBAEieqAUAIHmiFgCA\n5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACSl5vtOywUCtHYWNuWbmhoiOHh4cjn85HLzfpDYga1\ntrbWe4Saa2xszOTjOmq+/DzaYzbYYzZkfY8R82eX0zHrz0q5XK75MfP5fHR2dsbQ0FBUq9WaH5/6\nOXToUL1HqLnW1tZMPq6j5svPoz1mgz1mQ9b3GDFzuywWizU7Vr05/QAAgOSJWgAAkidqAQBInqgF\nACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkidqAQBInqgFACB5ohYAgOSJWgAAkper\n9wDwQW688cZ6j8DP6LHHHqv3CHBCWf/flkceeaTeI8Cs80otAADJE7UAACRP1AIAkDxRCwBA8kQt\nAADJE7UAACRP1AIAkDzvUwvwM7j22mvrPQKcUNbfhzfLvMfwz84rtQAAJE/UAgCQPFELAEDyRC0A\nAMkTtQAAJE/UAgCQPFELAEDyvE8tMCM+/vGP13sEAOYRr9QCAJA8UQsAQPJELQAAyavJObXDw8Px\nyCOPxGuvvRZtbW1x9dVXR3d3dy0ODQAAJ1WTqN28eXM0NTXFZz/72di9e3d885vfjKVLl8bixYtr\ncXgAAPhA0z79oFKpxEsvvRRr166NQqEQZ511VqxcuTJeeOGFWswHAAAnNe1Xavft2xeNjY1x2mmn\njV+2ZMmS2LFjRwwMDMTg4OCE21cqlWhvb5/u3U6Qy+Um/AkAkKJ8Pn/cy7XOyU37malUKlEoFCZc\n1tLSEuVyObZu3Rq9vb0TrluzZk2sXbt2unc7wcDAQGzZsiV6enqiWCxOuO65556r6X0xcwYGBmLr\n1q3R09MTHR0d9R6Hn5E9ZoM9ZoM9ZscHtQ7vmnbUNjc3R7lcnnBZuVyOQqEQPT09sXLlygnXLViw\nYLp3+T6Dg4PR29sbK1eu9EObMHvMBnvMBnvMBnvMDrs8uWlH7amnnhpHjhyJffv2xamnnhoREbt3\n745SqRQdHR2eeAAAZty0f1Gsubk5urq6YsuWLVGpVOKNN96IH//4x3HJJZfUYj4AADipmpxtfP31\n18e3v/3tuPfee6O1tTWuv/56b+cFAMCsqUnUtrW1xSc/+claHOpnsmDBglizZs2MnK/L7LHHbLDH\nbLDHbLDH7LDLk2sYGxsbq/cQAAAwHcm82dlkP4p3bGwsvvvd78bzzz8fERGrV6+Oa6+9NhoaGmZ7\nZI5jsnv8wQ9+ENu2bYt33nkn2tra4sMf/nBcccUVdZiYE5nqx2OPjIzE3//930elUok//MM/nMVJ\n+SBT2ePOnTvjO9/5TuzatSuam5vjyiuvjF/4hV+Y5Yk5nsnucWRkJB577LF45ZVXYnR0NM4888xY\nv369X+qeA5555pnYtm1b7N27Ny6++OLYsGHDCW/79NNPx1NPPRUjIyPR1dUV69ev9/61kVDUTvaj\neLdu3RqvvPJK3HXXXdHQ0BD/8i//EsViMT784Q/XaXLea7J7HBsbiw0bNsSSJUviwIED8a//+q/R\n0dERP/dzP1enyTnWVD8e+4c//GG0t7dHpVKZ5Un5IJPd49DQUHz961+Pj33sY7Fq1aoYHR2NgYGB\nOk3NsSa7x//8z/+Mt956K37rt34rCoVCPProo7F58+b4xCc+UafJOeqUU06Jj370o/Haa69FtVo9\n4e1effXVeOqpp+JTn/pUnHLKKfFv//ZvsWXLlrj22mtncdq5adrvfjAbpvJRvNu2bYvLL788Fi5c\nGB0dHfGLv/iLsW3btjpMzbGmssePfOQjsWzZsmhqaorTTjstVq5cGW+++WYdpuZ4pvrx2AcOHIi+\nvr648sorZ3lSPshU9vj000/H+eefH93d3ZHL5aJQKESpVKrD1BxrKns8ePBgnHfeebFgwYLI5/Nx\n8cUXR39/fx2m5lirVq2Krq6uaG1t/cDbbdu2LVavXh2LFy+O1tbWWLNmjc75P0lE7Yk+ivd4P4j9\n/f2xdOnSk96O2TeVPb7X2NhYvPHGG/4FOodMdZebN2+Oq6++2v89NsdMZY9vvfVWtLa2xn333Rdf\n+tKX4pvf/GYcPHhwNsflBKayx9WrV8ebb74ZAwMDUalUoq+vL84///zZHJdpOl7nDA0NxfDwcB2n\nmhuS+DfMB30U78lu29LSEpVKJcbGxpxXW2dT2eN7ff/734+xsbFYvXr1TI7HFExlly+//HIcOXIk\nurq64vXXX5+tEZmEqexxYGAgdu3aFXfccUcsXrw4Hn/88XjooYfi137t12ZrXE5gKns89dRTY+HC\nhfHVr341GhoaYsmSJXHdddfN1qjUwPE6J+LdT3Nta2ur11hzQhKv1H7QR/Ge7Lblcjmam5sF7Rww\nlT0e9cwzz8QLL7wQt99+u1f55pDJ7rJSqcTjjz/uX5pz1FR+JvP5fHR1dcXy5csjn8/HVVddFW++\n+WYcPnx4tsblBKayx02bNsXIyEj88R//cdxzzz3R1dUV3/jGN2ZrVGrgeJ0TER/479L5Iomofe9H\n8R519KN4j1UqlWLPnj0nvR2zbyp7jIh4/vnn46mnnoo77rgjFi5cOFtjMgmT3eW+ffvi4MGD8U//\n9E9x7733xgMPPBCDg4Nx7733xoEDB2Z7bI4xlZ/JJUuWHPcY3hWy/qayx927d8ell14abW1tkcvl\n4ud//ufjf//3f2NoaGg2R2Yajtc57e3t8/5V2ohEonYqH8V7ySWXxNNPPx0DAwMxMDAQTz/9dFx6\n6aV1mJpjTWWPfX198cQTT8Qdd9wRixYtqsO0fJDJ7nLx4sXx+7//+3HXXXfFXXfdFTfeeGO0t7fH\nXXfd5T9U5oCp/Exeeuml8corr8SuXbtidHQ0nnzyyTjzzDNP+kstzLyp7HH58uXxwgsvxOHDh2N0\ndDSeffbZOOWUU6K9vb0Ok/Neo6OjUa1WY2xsLMbGxqJarcbo6Oj7bnfJJZfE888/H3v37o1Dhw7F\nk08+qXP+TzIfvjA8PBzf/va3Y/v27dHa2hrXXHNNdHd3x44dO+LrX/963HPPPRHx7qsGjz/++Pj7\n1F522WXep3YOmewe/+Zv/iYGBgaiqalp/Hu7u7vjhhtuqNfoHGOyu3yv119/PR5++GHvUzuHTGWP\nzz77bDz55JNRrVbjzDPPjOuvv95/nMwRk93j8PBwPPbYY/Haa6/F6OhoLF68OH75l385VqxYUedH\nwJYtW6LFqkbsAAAD7ElEQVS3t3fCZWvWrInVq1fH1772tfjt3/7t6OzsjIh33yLxBz/4QVSr1Vi1\napX3qf0/yUQtAACcSBKnHwAAwAcRtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDy\nRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAgCQPFELAEDyRC0AAMkTtQAAJE/UAiRs\nZGSk3iMAzAmiFuAYZ599dnz5y1+O7u7uWLhwYdx2221x+PDhuP/+++MjH/nIhNs2NDTEq6++GhER\nn/70p+Mzn/lMfPzjH48FCxbEFVdcEbt3747f+73fi2KxGB/60Ifiv/7rvyZ1/3/xF38Rq1atimKx\nGHfeeWccPnw4IiK+//3vx4oVK+Kv/uqvYunSpXHnnXfG22+/HevXr4/Ozs5YtGhRXHnllXHkyJHa\nPzEAc5ioBTiOf//3f4/vfOc78frrr0dfX1/cf//9k/6+L3zhC/H2229HoVCIyy+/PC677LJ4++23\n45Zbbok/+IM/mNRxvvGNb8R//Md/xGuvvRb/8z//E1/4whfGr9u9e3fs378/duzYEf/4j/8YX/nK\nV2LFihXR398fe/bsiS9+8YvR0NDwszxsgGSJWoDj+N3f/d1YtmxZLFq0KG644YbYtm3bpL5vw4YN\n0dPTEy0tLbFhw4ZoaWmJO+64I5qamuK2226b1Cu1ERG/8zu/E2eccUYsWrQo7rnnnvjWt741fl1j\nY2P8+Z//eRQKhWhtbY18Ph+7du2KHTt2RD6fjyuvvFLUAvOOqAU4jqVLl47/va2tLQYHByf1fUuW\nLBn/e2tr6/u+nuxxzjjjjPG/n3XWWbFz587xr0ulUrS0tIx//Ud/9Edx/vnnxy/90i/FueeeG3/5\nl385qfsAyBJRCzBJ7e3tMTw8PP717t27Z+y+3nzzzfG/v/HGG7Fs2bLxr499FfaUU06Jr3zlK7F9\n+/Z49NFH46tf/Wo88cQTMzYbwFwkagEm6ZJLLon//u//jm3btsXhw4fj85///Izd19e+9rV46623\nYv/+/fHFL34xbrvtthPeduPGjfHqq6/G2NhYdHR0RFNTUzQ1Nc3YbABzkagFmKQLL7ww/uzP/iyu\nueaauOCCC973Tgi1dPvtt4+fTnDuuefGn/7pn57wtj/5yU/immuuiQULFsTll18en/nMZ+Kqq66a\nsdkA5qKGsbGxsXoPAcD/d/bZZ8d9990X11xzTb1HAUiGV2oBAEhert4DAMw3b7zxRqxateq41730\n0kuzPA1ANjj9AACA5Dn9AACA5IlaAACSJ2oBAEieqAUAIHmiFgCA5IlaAACS9/8AXMPkla8Vx9EA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25074450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (287474357)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sqlContext.sql(\"\"\"select project_name, count(*) as num_prs\n",
    "                  from pullreqs\n",
    "                  group by project_name having num_prs < 1000\"\"\").toPandas()\n",
    "r['num_prs'] = r['num_prs'] / 1000;\n",
    "r\n",
    "\n",
    "ggplot(aes(x='num_prs'), data = r) + geom_histogram(binwidth = .01)\n",
    "# ggplot(aes(x = 'num_prs'), data=r) + \\\n",
    "#     geom_histogram(binwidth=.001) + \\\n",
    "#     scale_x_log() + \\\n",
    "#     ylab(\"Num projects\") + xlab(\"Num PRs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much time does it take to close a PR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the majority (75%) of all pull requests are closed in less than 2 days, while 50% are closed in just 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mergetime_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.744971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.975450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.619792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.921528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74%</th>\n",
       "      <td>2.739444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4.048611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>11.204861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>22.791146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>880.227083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mergetime_minutes\n",
       "count       13136.000000\n",
       "mean            5.744971\n",
       "std            24.975450\n",
       "min             0.000694\n",
       "50%             0.619792\n",
       "60%             0.921528\n",
       "74%             2.739444\n",
       "80%             4.048611\n",
       "90%            11.204861\n",
       "95%            22.791146\n",
       "max           880.227083"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('mergetime_minutes').where('mergetime_minutes > 0.0').toPandas().apply(lambda x: x / 1440).describe(percentiles=[0.6, 0.74, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main team members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mergetime_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.347929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.160871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.547222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.872222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74%</th>\n",
       "      <td>2.255931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>3.807639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>9.061181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>18.607049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>880.227083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mergetime_minutes\n",
       "count       11572.000000\n",
       "mean            4.347929\n",
       "std            17.160871\n",
       "min             0.000694\n",
       "50%             0.547222\n",
       "60%             0.872222\n",
       "74%             2.255931\n",
       "80%             3.807639\n",
       "90%             9.061181\n",
       "95%            18.607049\n",
       "max           880.227083"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('mergetime_minutes').\\\n",
    "    where('mergetime_minutes > 0.0 and main_team_member = true').\\\n",
    "    toPandas().apply(lambda x: x / 1440).\\\n",
    "    describe(percentiles=[0.6, 0.74, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not main team members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mergetime_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.081655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.226121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.057986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>2.130139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74%</th>\n",
       "      <td>6.796431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>11.614167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>32.137361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>79.802569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>694.952778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mergetime_minutes\n",
       "count        1564.000000\n",
       "mean           16.081655\n",
       "std            54.226121\n",
       "min             0.000694\n",
       "50%             1.057986\n",
       "60%             2.130139\n",
       "74%             6.796431\n",
       "80%            11.614167\n",
       "90%            32.137361\n",
       "95%            79.802569\n",
       "max           694.952778"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('mergetime_minutes').\\\n",
    "    where('mergetime_minutes > 0.0 and main_team_member = false').\\\n",
    "    toPandas().apply(lambda x: x / 1440).\\\n",
    "    describe(percentiles=[0.6, 0.74, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close time for unmerged pull requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifetime_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.248848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.049190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.719444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>547.624306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lifetime_minutes\n",
       "count        361.000000\n",
       "mean          11.248848\n",
       "std           44.049190\n",
       "min            0.000694\n",
       "25%            0.050000\n",
       "50%            0.719444\n",
       "75%            4.987500\n",
       "max          547.624306"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('lifetime_minutes').\\\n",
    "    where('mergetime_minutes = 0.0 and lifetime_minutes > 0.0').\\\n",
    "    toPandas().\\\n",
    "    apply(lambda x: x / 1440).\\\n",
    "    describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of pull requests\n",
    "#### Number of commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_commits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.264421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.398812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>258.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_commits\n",
       "count  15377.000000\n",
       "mean       4.264421\n",
       "std       13.398812\n",
       "min        1.000000\n",
       "50%        2.000000\n",
       "80%        4.000000\n",
       "90%        8.000000\n",
       "95%       13.000000\n",
       "max      258.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('num_commits').\\\n",
    "    toPandas().\\\n",
    "    describe(percentiles=[0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.424725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56.785824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2687.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       files_changed\n",
       "count   15377.000000\n",
       "mean       14.424725\n",
       "std        56.785824\n",
       "min         0.000000\n",
       "50%         3.000000\n",
       "80%        12.000000\n",
       "90%        26.000000\n",
       "95%        52.000000\n",
       "max      2687.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('files_changed').\\\n",
    "    toPandas().\\\n",
    "    describe(percentiles=[0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of changed lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.493103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>92.717275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>48.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>113.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>192.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>842.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        src_churn\n",
       "count  290.000000\n",
       "mean    42.493103\n",
       "std     92.717275\n",
       "min      1.000000\n",
       "50%     11.000000\n",
       "80%     48.400000\n",
       "90%    113.500000\n",
       "95%    192.950000\n",
       "max    842.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('src_churn').\\\n",
    "    where('src_churn > 0.0').\\\n",
    "    toPandas().\\\n",
    "    describe(percentiles=[0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion and code review\n",
    "#### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.936073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.941817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_comments\n",
       "count  15377.000000\n",
       "mean       2.936073\n",
       "std        7.941817\n",
       "min        0.000000\n",
       "50%        1.000000\n",
       "80%        4.000000\n",
       "90%        7.000000\n",
       "95%       12.000000\n",
       "max      240.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('num_comments').\\\n",
    "    toPandas().\\\n",
    "    describe(percentiles=[0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between size and merge decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Commits: 0.167528442551\n",
      "Files changed: 0.00724571354084\n",
      "Lines changed: 0.00828534249669\n"
     ]
    }
   ],
   "source": [
    "print 'Num Commits: ' + str(aux['num_commits'].corr(aux['merged'], method='spearman'))\n",
    "print 'Files changed: ' + str(aux['src_files'].corr(aux['merged'], method='spearman'))\n",
    "print 'Lines changed: ' + str(aux['src_churn'].corr(aux['merged'], method='spearman'))\n",
    "# aux['num_commits'].corr(aux['merged'], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between number of comments and pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge decision: 0.335960922278\n",
      "Merge time: 0.523524975596\n"
     ]
    }
   ],
   "source": [
    "print 'Merge decision: ' + str(aux['num_comments'].corr(aux['merged'], method='spearman'))\n",
    "print 'Merge time: ' + str(aux['num_comments'].corr(aux['mergetime_minutes'], method='spearman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many people work on PRs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>290386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.032302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.312486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_participants\n",
       "count     290386.000000\n",
       "mean           1.032302\n",
       "std            1.312486\n",
       "min            0.000000\n",
       "25%            0.000000\n",
       "50%            1.000000\n",
       "75%            2.000000\n",
       "max           50.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('num_participants').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many comments do PRs receive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>290386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.410030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.652631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>475.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_comments\n",
       "count  290386.000000\n",
       "mean        2.410030\n",
       "std         6.652631\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         2.000000\n",
       "max       475.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('num_comments').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How balanced is the dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important for our machine learning task to check whether "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merged  count\n",
       "0    True  13136\n",
       "1   False   2241"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('merged').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting pull request merges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to create a predictor that given a set of _features_ (metrics about various aspects of a single PR), it will come up with a _response_ (prediction): either **True** (PR will be merged) or **False** (PR will not be merged). Our predictor is a typical binary classification task.\n",
    "\n",
    "There are various algorithms that given a set of _feature vectors_ (vectors/arrays of numerical values that correspond to our features) they will come up with a _model_ to predict an outcome. The ones we will be using are:\n",
    "\n",
    "* [Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "* [Linear Support Vector Machines](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "* [Decision trees](https://en.wikipedia.org/wiki/Decision_tree)\n",
    "* [Random Forests](https://en.wikipedia.org/wiki/Random_forest)\n",
    "* [Gradient Boosting Machines](https://en.wikipedia.org/wiki/Gradient_boosting)\n",
    "\n",
    "The first step in any binary classification task is to define the features and the response variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] >= threshold:\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_time (row):\n",
    "    minutes = row['mergetime_minutes']\n",
    "    if minutes < 24 * 60:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux0 = deepcopy(aux)\n",
    "\n",
    "correlation(aux0, 0.7)\n",
    "\n",
    "# print aux2.columns\n",
    "feature_cols = []\n",
    "for i in range(3, len(aux0.columns)):\n",
    "    if aux0.columns[i] != 'merged' and aux0.columns[i].find(\"minute\") == -1 and aux0.columns[i] != 'first_response':\n",
    "        if aux0[aux0.columns[i]].dtype != 'object':\n",
    "            feature_cols.append(aux0.columns[i])\n",
    "\n",
    "# feature_cols = ['prior_interaction_pr_events', 'team_size', 'num_participants', 'num_issue_comments']\n",
    "\n",
    "\n",
    "response = 'merged'\n",
    "aux1 = aux.sample(15200);\n",
    "aux2 = aux.sample(15200);\n",
    "aux2['mergetime_minutes'] = aux2['mergetime_minutes'].astype(int)\n",
    "aux2['mergetime'] = aux2.apply(lambda row: label_time(row), axis = 1)\n",
    "\n",
    "df1 = sqlContext.createDataFrame(aux1);\n",
    "df2 = sqlContext.createDataFrame(aux2);\n",
    "\n",
    "# We drop any possible duplicates and cache the resulting data frame\n",
    "data = df1.select(feature_cols).dropDuplicates().cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most machine learning algorithm implementations work with numerical vectors. For this reason, we need to convert all features that are not of type `Integer` in our source data frame to numeric. Fortunately, we only have a few `Boolean` features that can be represeted as `Integer`s by assigning 1 to True values and 0 to False with a simple type cast. If we had factors (those take values from a predefined set) as features, we would need to use a `StringIndexer` on them.\n",
    "\n",
    "SparkML needs all features to be in a single vector per data point. For this, we use the `VectorAssember` transformation.\n",
    "\n",
    "SparkML makes use of pipelines to organize the application of transformations on data frames. In our case, we only need to build a pipeline that performs the `VectorAssember` step, but those pipelines can be arbitrarily large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# All boolean columns\n",
    "boolean = ['intra_branch', 'main_team_member', \n",
    "           'social_connection', 'conflict', 'forward_links']\n",
    "boolean_out = map(lambda x: x + \"_int\", boolean)\n",
    "\n",
    "# Update the feature_cols with information about the new column names\n",
    "feature_cols = [item for item in set(feature_cols) \\\n",
    "                if item not in set(boolean)] + \\\n",
    "                boolean_out\n",
    "\n",
    "# Type cast boolean columns to Integers (convert to numeric)\n",
    "for x in boolean:\n",
    "    df1 = df1.withColumn(x + \"_int\", df1[x].cast(IntegerType()))\n",
    "    df2 = df2.withColumn(x + \"_int\", df2[x].cast(IntegerType()))\n",
    "df1 = df1.withColumn(\"merged_int\", df1['merged'].cast(IntegerType()))\n",
    "df2 = df2.withColumn(\"merged_int\", df2['merged'].cast(IntegerType()))\n",
    "\n",
    "# Convert feature columns to a numeric vector\n",
    "assembler_features = VectorAssembler(inputCols=feature_cols, \n",
    "                                     outputCol='features')\n",
    "\n",
    "# Construct and execute a pipeline, cache the results.\n",
    "pipeline = Pipeline(stages=[assembler_features])\n",
    "allData = pipeline.fit(df1).transform(df1).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have our data in the desirable format, we can start experimenting with machine learning algorithms. For that, we need to have 2 datasets: one to apply our algorithm on and one to test the resulting model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13704\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = allData.randomSplit([0.9, 0.1], seed=42)\n",
    "\n",
    "print trainingData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of running an ML algorithm on a dataset consists of the following steps:\n",
    "\n",
    "1. Train a model\n",
    "2. Apply the trained model on the test set, collect performance metrics\n",
    "3. Tune the ML algorithm and repeat\n",
    "\n",
    "To evaluate the training (step 2), and since we are using binary classification, we need to test how well our model can predict against a ground truth included in the test set. The result of step 2 is the so called [_confusion matrix_](https://en.wikipedia.org/wiki/Confusion_matrix). The confusion matrix looks like this:\n",
    "\n",
    "|              |       |Ground truth |\n",
    "|--------------|-------|-------------|\n",
    "|              |       | True | False|\n",
    "| *Prediction* | True  | *TP* | *FP* | \n",
    "|              | False | *FN* | *TN* |\n",
    "\n",
    "\n",
    "Using this table we can come up with many metrics that capture several aspects of the classification performance, such as:\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + FP + FN + TN} $$\n",
    "\n",
    "$$ False\\ positive\\ rate = \\frac{FP}{FP + TN} $$\n",
    "\n",
    "When predicting, most binary classification algorithms return the *probability* that a result is either true or false, rather than the actual result; depending on how strong our prediction requirements are, we need to vary the *threshold* after which we start believing a prediction. This threshold is usually set at 0.7, so if our classifier reports a probability of 0.73 for a classification result being True, we take its value as True.\n",
    "\n",
    "By varying this threshold from 0.5 to 1, we can see how strong our classifier believes its results are; we can then test them against reality (our ground truth) to see how strong they _actually_ are. To do so, we plot the classifier's recall (or True Positive Rate) against its False Positive Rate for various values of threshold. This will result in a plot (called the [Receiver Operating Characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve) that looks like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A ROC curve](roccurves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under each curve can be calculated; this results in a composite metric (Area Under the (ROC) Curve) that describes the predictive power of our classifier against a random classifier. AUC enables comparisons of classifiers with each other and is especially useful as a metric in case of unbalanced datasets, as in our case.\n",
    "\n",
    "For our purposes, we will be using the AUC metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "## Calculate and return the AUC metric\n",
    "def evaluate(testData, predictions):\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"merged_int\", \n",
    "                                              rawPredictionCol=\"rawPrediction\")\n",
    "    print \"AUC: %f\" % evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other regressions, binary logistic regression does polynomial fiting: it attempts to compute the co-efficients $a$ and $b$ and the intercept $c$ of a polynomial of the form $y = ax_1 + bx_2+ c$, where $x_1, x_2$ and $y$ come from the training data, in order to maximize a training criterion (the workings under the hood are very different though). \n",
    "\n",
    "With default settings, it does a terrible job on our dataset, with an AUC of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.500000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, \n",
    "                        elasticNetParam=0.8 ,labelCol=\"merged_int\")\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "evaluate(testData, lrModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs attempt to partition datasets using hyperplanes in a way that dataset points are as far as possible in high-dimentional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.807587\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"merged_int\")\n",
    "\n",
    "lsvcModel = lsvc.fit(trainingData)\n",
    "evaluate(testData, lsvcModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision (classification) tree is a tree structure where intermediate nodes represent a decision that partitions the data while leafs represent a classification class. Decision trees are easy to train and very intuitive to interpret, as they mimic human decision making. Unfortunately though they tend to overfit (especially if we allow them to grow to very big depths) and not robust against data variation.\n",
    "\n",
    "On our dataset, they perform rather well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.836371\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"merged_int\")\n",
    "\n",
    "dtModel = dt.fit(trainingData)\n",
    "evaluate(testData, dtModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests work by building many decision trees. For buildingeach tree, a (configurable) number of features is selected randomly, while the trees are grown up to a (configurable) depth. Then, at prediction time, all trees are asked about their \"opinion\" on the input feature values, and the majority vote wins.\n",
    "\n",
    "RF are a very easy algorithm to train and default values usually lead to good perfomance out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.908029\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier as RF\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "rf = RF(labelCol='merged_int', featuresCol='features', \n",
    "        numTrees=100, maxDepth=5)\n",
    "rfModel = rf.fit(trainingData)\n",
    "evaluate(testData, rfModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One particularly interesting property of tree ensemble methods, such as random forests, is that they provide us with an indication of which factors are most influential whed doing a classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>prior_interaction_pr_events</td>\n",
       "      <td>0.162591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>num_participants</td>\n",
       "      <td>0.151652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>num_issue_comments</td>\n",
       "      <td>0.104620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stars</td>\n",
       "      <td>0.096960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prior_interaction_issue_events</td>\n",
       "      <td>0.052479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>prior_interaction_issue_comments</td>\n",
       "      <td>0.047444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>prior_interaction_pr_comments</td>\n",
       "      <td>0.044977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_lines</td>\n",
       "      <td>0.039904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>description_length</td>\n",
       "      <td>0.037093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>prior_interaction_commits</td>\n",
       "      <td>0.033226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             feature  importance\n",
       "34       prior_interaction_pr_events    0.162591\n",
       "26                  num_participants    0.151652\n",
       "36                num_issue_comments    0.104620\n",
       "16                             stars    0.096960\n",
       "9     prior_interaction_issue_events    0.052479\n",
       "20  prior_interaction_issue_comments    0.047444\n",
       "22     prior_interaction_pr_comments    0.044977\n",
       "10                        test_lines    0.039904\n",
       "6                 description_length    0.037093\n",
       "37         prior_interaction_commits    0.033226"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=zip(feature_cols, rfModel.featureImportances), \n",
    "             columns=(\"feature\", \"importance\")).\\\n",
    "            sort_values(\"importance\", ascending=False).\\\n",
    "            head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting refers to a general class of algorithms that try create strong predictors using ensembles of weak ones (e.g. decision trees). After training a weak classifier, boosting algorithms will weight training examples in a way that will favour those that were misclassifed by the current ensemble. Thus, new weak classifiers will be using more training data that were misclassified.\n",
    "\n",
    "Gradient boosting is a form of boosting that uses [gradient decent](https://en.wikipedia.org/wiki/Gradient_boosting) as an optimization method and stopping criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.862469\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(maxIter=10, maxDepth=5, \n",
    "                    labelCol=\"merged_int\", seed=42)\n",
    "gbtModel = gbt.fit(trainingData)\n",
    "evaluate(testData, gbtModel.transform(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>prior_interaction_pr_events</td>\n",
       "      <td>0.155641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>description_length</td>\n",
       "      <td>0.095948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_size</td>\n",
       "      <td>0.087230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>num_participants</td>\n",
       "      <td>0.069822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>social_connection_int</td>\n",
       "      <td>0.062853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>num_issue_comments</td>\n",
       "      <td>0.058130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_lines</td>\n",
       "      <td>0.052535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stars</td>\n",
       "      <td>0.043957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>workload</td>\n",
       "      <td>0.040380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>main_team_member_int</td>\n",
       "      <td>0.040031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "33  prior_interaction_pr_events    0.155641\n",
       "5            description_length    0.095948\n",
       "0                     team_size    0.087230\n",
       "25             num_participants    0.069822\n",
       "38        social_connection_int    0.062853\n",
       "35           num_issue_comments    0.058130\n",
       "9                    test_lines    0.052535\n",
       "15                        stars    0.043957\n",
       "24                     workload    0.040380\n",
       "37         main_team_member_int    0.040031"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=zip(feature_cols, gbtModel.featureImportances), \n",
    "             columns=(\"feature\", \"importance\")).\\\n",
    "            sort_values(\"importance\", ascending=False).\\\n",
    "            head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15200\n"
     ]
    }
   ],
   "source": [
    "data = df2.select(feature_cols).dropDuplicates().cache()\n",
    "pipeline = Pipeline(stages=[assembler_features])\n",
    "allData = pipeline.fit(df2).transform(df2).cache()\n",
    "(trainingData, testData) = allData.randomSplit([0.9, 0.1], seed=42)\n",
    "\n",
    "print allData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['team_size', 'test_churn_open', 'requester_succ_rate', 'num_commit_comments_open', 'files_modified_open', 'files_deleted', 'new_entropy', 'description_length', 'commits_on_files_touched', 'perc_external_contribs', 'prior_interaction_issue_events', 'test_lines', 'num_comments', 'at_mentions_description', 'doc_files_open', 'files_deleted_open', 'prior_interaction_commit_comments', 'followers', 'stars', 'sloc', 'num_pr_comments', 'test_cases', 'files_changed_open', 'num_issue_comments', 'prior_interaction_issue_comments', 'other_files_open', 'github_id', 'prior_interaction_pr_comments', 'prev_pullreqs', 'tests_deleted_open', 'workload', 'num_participants', 'files_added_open', 'num_commits', 'entropy_diff', 'hotness', 'src_files_open', 'at_mentions_comments', 'test_churn', 'num_commit_comments', 'asserts', 'prior_interaction_pr_events', 'src_churn_open', 'tests_added_open', 'prior_interaction_commits', 'intra_branch_int', 'main_team_member_int', 'social_connection_int', 'conflict_int', 'forward_links_int']\n"
     ]
    }
   ],
   "source": [
    "print feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.500000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, \n",
    "                        elasticNetParam=0.8 ,labelCol=\"mergetime\")\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "evaluate(testData, lrModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.825126\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1,labelCol=\"mergetime\")\n",
    "\n",
    "lsvcModel = lsvc.fit(trainingData)\n",
    "evaluate(testData, lsvcModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.688113\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"mergetime\")\n",
    "\n",
    "dtModel = dt.fit(trainingData)\n",
    "evaluate(testData, dtModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.855543\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier as RF\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "rf = RF(labelCol='mergetime', featuresCol='features', \n",
    "        numTrees=100, maxDepth=5)\n",
    "rfModel = rf.fit(trainingData)\n",
    "evaluate(testData, rfModel.transform(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>num_issue_comments</td>\n",
       "      <td>0.198043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>num_participants</td>\n",
       "      <td>0.193517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num_pr_comments</td>\n",
       "      <td>0.119250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>at_mentions_comments</td>\n",
       "      <td>0.082843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>workload</td>\n",
       "      <td>0.074615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>num_commits</td>\n",
       "      <td>0.047576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tests_deleted_open</td>\n",
       "      <td>0.024480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>prior_interaction_pr_events</td>\n",
       "      <td>0.023554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>requester_succ_rate</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>description_length</td>\n",
       "      <td>0.022336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "36           num_issue_comments    0.198043\n",
       "26             num_participants    0.193517\n",
       "18              num_pr_comments    0.119250\n",
       "32         at_mentions_comments    0.082843\n",
       "25                     workload    0.074615\n",
       "28                  num_commits    0.047576\n",
       "24           tests_deleted_open    0.024480\n",
       "34  prior_interaction_pr_events    0.023554\n",
       "2           requester_succ_rate    0.022734\n",
       "6            description_length    0.022336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=zip(feature_cols, rfModel.featureImportances), \n",
    "             columns=(\"feature\", \"importance\")).\\\n",
    "            sort_values(\"importance\", ascending=False).\\\n",
    "            head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen already, most algorithms contain many knobs (configuration parameters) that we can use to tune the model building. Those are often called _hyper parameters_. To tune them in a systematic manner, Spark ML offers a tool called `Grid` that accepts value ranges for all hyper parameters.\n",
    "\n",
    "For algorithms that are not robust against overfitting (building a model that predicts very well the training set but fails to generalize), for example decision trees, it is often advisable to train it on various instances of the training set and report average precision/recall/F1/AUC scores. This process is called _cross-validation_. In typical random selection $k$-fold cross validation, the algorith will randomly sample the dataset $k$ times (usually 80%/20% for training and evaluation data), build a model and evaluate it on the remaining training data. Cross validation can also be used as a guard against overfiting when trying to find the optimal model when doing hyper-parameter optimization.\n",
    "\n",
    "In the following snippet we attempt to improve our decision tree model by tuning several parameters. As we can see, the defaults are pretty ok as we only achieve marginal improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [4, 8])\n",
    "             .addGrid(dt.maxBins, [16, 32, 64])\n",
    "             .addGrid(dt.minInstancesPerNode, [1, 2],)\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"merged_int\",\n",
    "                                          rawPredictionCol=\"rawPrediction\")\n",
    "cv = CrossValidator(estimator=dt, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, numFolds=3)\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.791859\n"
     ]
    }
   ],
   "source": [
    "evaluate(testData, cvModel.transform(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4371ae808e87c17e3c9b) of depth 8 with 169 nodes"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving prediction of minority case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC metric, while comprehensive, tells us half the truth about the prediction performance. As we can see below, the best algorithm (GBT) consistently mispredicts the `merged = False` case, even though it does a good job with the `True` case. This probably happens because the classifier overfits to the majority case (`merged = True` in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM missprediction rate: False: 100.000000, True: 0.001285\n",
      "RF missprediction rate: False: 85.828935, True: 1.278559\n",
      "GBT missprediction rate: False: 70.999928, True: 3.000437\n",
      "CVModel missprediction rate: False: 73.689538, True: 2.821824\n"
     ]
    }
   ],
   "source": [
    "def missprediction_rate(model, testData):\n",
    "    predictions = model.transform(testData)\n",
    "    predictions = predictions.\\\n",
    "        select(predictions.merged_int.cast(\"double\").alias('ground_truth'), \\\n",
    "               'prediction')\n",
    "\n",
    "    true_predictions = predictions.\\\n",
    "                       where(predictions.ground_truth == 1.0).\\\n",
    "                       count()\n",
    "    false_predictions = predictions.\\\n",
    "                        where(predictions.ground_truth == 0.0).\\\n",
    "                        count()\n",
    "    true_misspredictions = predictions.\\\n",
    "                          where(predictions.ground_truth != predictions.prediction).\\\n",
    "                          where(predictions.ground_truth == 1.0).\\\n",
    "                          count()\n",
    "    false_misspredictions = predictions.\\\n",
    "                            where(predictions.ground_truth != predictions.prediction).\\\n",
    "                            where(predictions.ground_truth == 0.0).\\\n",
    "                            count()\n",
    "\n",
    "    return ((float(false_misspredictions) / false_predictions) * 100),\\\n",
    "        ((float(true_misspredictions) / true_predictions) * 100)\n",
    "\n",
    "print \"SVM missprediction rate: False: %f, True: %f\" % \\\n",
    "        missprediction_rate(lsvcModel, testData)\n",
    "print \"RF missprediction rate: False: %f, True: %f\" % \\\n",
    "        missprediction_rate(rfModel, testData)\n",
    "print \"GBT missprediction rate: False: %f, True: %f\" % \\\n",
    "        missprediction_rate(gbtModel, testData)\n",
    "print \"CVModel missprediction rate: False: %f, True: %f\" % \\\n",
    "        missprediction_rate(cvModel, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution to this problem is to 'penalize' the classifier learning by removing datapoints during learning. Specifically, we will keep all the minority class items and subsample our majority class to 2x the number of the majority class items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minority_class = allData.where(allData.merged_int == 0)\n",
    "majority_class = allData.where(allData.merged_int != 0).\\\n",
    "    sample(False, 0.5).\\\n",
    "    limit(minority_class.count() * 2)\n",
    "\n",
    "balancedAllData = minority_class.union(majority_class)\n",
    "(balancedTrainingData, balancedTestData) = \\\n",
    "        balancedAllData.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrain RF on our balanced dataset. What we see is that while the AUC is roughly the same, the missprediction rate has been vastly improved in the `False` case, while became only slightly worse in the `True` case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.783390\n",
      "Balanced RF missprediction rate: False: 64.615050, True: 6.347009\n"
     ]
    }
   ],
   "source": [
    "balancedRfModel = rf.fit(balancedTrainingData)\n",
    "evaluate(balancedTestData, balancedRfModel.transform(balancedTestData))\n",
    "\n",
    "print \"Balanced RF missprediction rate: False: %f, True: %f\" %\\\n",
    "    missprediction_rate(balancedRfModel, balancedTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, we also train a GBT classifier on the balanced dataset. The results are the same as in the RF case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.795024\n",
      "Balanced GBT missprediction rate: False: 54.965927, True: 8.678860\n"
     ]
    }
   ],
   "source": [
    "balancedGBTModel = gbt.fit(balancedTrainingData)\n",
    "evaluate(balancedTestData, balancedGBTModel.transform(balancedTestData))\n",
    "\n",
    "print \"Balanced GBT missprediction rate: False: %f, True: %f\" %\\\n",
    "    missprediction_rate(balancedGBTModel, balancedTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to the question of whether to use the default model or the balanced one boils down to priorities: do we care about the False case, even if it is relatively rare?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
